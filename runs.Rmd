```{r prep}
library(tidyverse)
library(here)
library(cowplot)
library(Seurat)
list.files("R/", full.names = TRUE) %>% map(., source)
data_dir <- ""
sample <- "Gau42k"
rc <- here(data_dir, sample, "HTO_counts.csv.gz")
rh <- here(data_dir, sample, "raw_feature_bc_matrix.h5")
rr <- here(data_dir, sample, "RNA_counts.csv.gz")
wl <- here(data_dir, sample, "barcodes.tsv.gz")
dir.create(here(data_dir, sample, "results"), showWarnings = FALSE)

#whitelist_rm = NULL
#whitelist_rm = "-1"
```

```{r run}
run_MULTIseqDemux(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/MULTIseqDemux.csv.gz"), 
  threshold = 10#,whitelist_rm = whitelist_rm
)

run_HTODemux(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/HTODemux.csv.gz"), 
  threshold = 10#,whitelist_rm = whitelist_rm
)

run_HTODemux_Libnorm(
  raw_counts = rc,
  whitelist = wl,
  threshold = 10,
  out_name = here(data_dir, sample, "results/HTODemux_Libnorm.csv.gz")#,whitelist_rm = whitelist_rm
)

run_demuxEM(
  raw_counts = rc,
  raw_h5 = rh,
  #raw_h5 = rr,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/demuxEM.csv.gz")#,whitelist_rm = whitelist_rm
)

run_HashSolo(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/HashSolo.csv.gz")#,whitelist_rm = whitelist_rm
)
```


```{r so_res}
so <- readRDS(here(data_dir, sample, "so.rds"))
so_backup <- so
resall <- map(
  c(
    #"HTODemux_margin1",
    "HTODemux",
    "HTODemux_Libnorm",
    "demuxEM",
    "HashSolo",
    "MULTIseqDemux"
  ),
  function(.x) {
    parse_results(here(data_dir, sample, "results", paste0(.x, ".csv.gz")), 
                  whitelist = Cells(so)) %>% 
      setNames(str_c(.x, "_", c("global", "local")))
  }) %>% bind_cols() %>% 
  mutate_at(.vars = vars(contains("_local")), .funs = function(.y) {str_replace_all(.y, "-", "_")})

# resall <- resall %>% find_consensus() %>% 
#   find_consensus(c("HTODemux_Libnorm_local", "demuxEM_local"), new_col = "HTO.EM")

so <- AddMetaData(so, resall)

sample_desc <- hash_data %>% filter(str_detect(sample, paste0("^", sample_id)))
ids <- sample_desc$ids %>% str_split("_") %>% unlist()
code1 <- sample_desc$code %>% str_replace("\\\\", "\\\\\\\\")
if (code1 == "") {
  code1 <- "id_hash"
}
demux <- so@meta.data %>%
  select(type = sample_desc$id_col, ends_with("_global")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(method = str_remove(method, "_global")) %>% 
  mutate(demux = ifelse(id_hash == "Singlet", "yes", "no")) %>% 
  group_by(method, demux) %>% 
  summarize(n = n()) %>% 
  na.omit() %>% 
  group_by(method) %>% 
  mutate(n = n/sum(n)) %>% 
  filter(demux == "yes")

rec <- so@meta.data %>%
  select(type = sample_desc$id_col, ends_with("_local")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(id_hash := !!rlang::parse_quo(code1, env = rlang::caller_env())) %>% 
  rename(true = type, pred = id_hash) %>%
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_miss = ifelse(true != pred, n, 0)) %>% 
  na.omit() %>% 
  group_by(method, true) %>% 
  summarize(recall = sum(correct)/(sum(correct) + sum(wrong_miss))) %>% 
  rename(id = true) %>% 
  mutate(method = str_remove(method, "_local")) %>% 
  filter(id %in% ids)

prec <- so@meta.data %>%
  select(type = sample_desc$id_col, ends_with("_local")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(id_hash := !!rlang::parse_quo(code1, env = rlang::caller_env())) %>% 
  rename(true = type, pred = id_hash) %>%
  filter(true %in% ids) %>% 
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_call = ifelse(true != pred, n, 0)) %>% 
  group_by(method, pred) %>% 
  summarize(precision = sum(correct)/(sum(correct) + sum(wrong_call))) %>% 
  filter(!(pred %in% c("Doublet", "Negative"))) %>% 
  rename(id = pred) %>% 
  mutate(method = str_remove(method, "_local")) %>% 
  filter(id %in% ids)

f1 <- full_join(prec, rec, by = c("method", "id")) %>% 
  replace_na(list(precision = 0, recall = 0)) %>%
  mutate(F1 = 2*precision*recall/(precision+recall)) %>% 
  group_by(method) %>% 
  summarize(meanF1 = mean(F1),
            precision = str_c(precision, collapse = ";"),
            recall = str_c(recall, collapse = ";")) %>% 
  mutate(meanF1 = ifelse(is.nan(meanF1), 0, meanF1))

type_ord <- so@meta.data %>% mutate(id := !!as.name(sample_desc$id_col)) %>% 
  select(type, id) %>%
  filter(id %in% ids) %>% 
  pull(type) %>% 
  table() %>% 
  sort() %>%
  names() %>%
  rev() # %>% intersect(ids)

df1 <- so@meta.data %>% 
  select(type, contains("_global")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "global") %>% 
  filter(!is.na(type)) %>% 
  group_by(type, method, global) %>% 
  summarise(n = n()) %>% 
  group_by(type, method) %>% 
  mutate(type = factor(type, levels = type_ord)) %>% 
  mutate(global = factor(global, levels = c("Negative", "Doublet", "Singlet"))) %>% 
  na.omit() %>% 
  mutate(freq = n/sum(n)) %>% 
  mutate(method = str_remove(method, "_global"))

cv <- df1 %>% filter(global == "Singlet") %>% group_by(method) %>% summarise(cv = sd(freq)/mean(freq)) %>% 
  mutate(cv_lab = str_c("cv=", sprintf("%.3f", round(cv, digits = 3)))) %>% 
  full_join(f1, by = "method") %>% 
  mutate(meanF1 = str_c("meanF1=", sprintf("%.3f", round(meanF1, digits = 3))))

g1 <- ggplot(df1, aes(x = type, y = freq)) +
  facet_grid(.~method) +
  geom_col(colour="black", aes(fill = global)) +
  theme_classic() +
  ylab("Hash calling") +
  theme(axis.title.x=element_blank()) +
  theme(legend.title=element_blank()) + 
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  geom_text(data = cv, aes(x = 1, y = 1.025, label = cv_lab), hjust = 0, size = 3.5) +
  geom_text(data = cv, aes(x = 1, y = 1.075, label = meanF1), hjust = 0, size = 3.5)

ggsave(here(data_dir, sample, "results/celltype_consensus.pdf"), g1, width = 10, heigh = 5)
write_csv(f1, here(data_dir, sample, "results/F1.csv"))
```

# aggregate results

```{r}
samples <- c("amc", "P1mc", "P2a", "A17k", "A45k", "hash18", "2hash_orig", "TEImix", "bench_CMO_nuclei", "bench_TotalSeqC_cells", "bench_LMO_MULTseq_cells", "bench_LMO_custom_cells")
res <- map(samples, function(x) {
  read_csv(here(data_dir, x, "results/F1.csv"))
})
# ns <- map(samples, function(x) {
#   so <- readRDS(here(data_dir, x, "so.rds"))
#   so$nCount_HTO
# })
names(res) <- samples
res2 <- do.call(rbind, res) %>% 
  rownames_to_column("sample") %>% 
  mutate(sample = str_remove(sample, "\\..+")) %>% 
  mutate(method = factor(method, levels = c("HashSolo", "demuxEM", "HTODemux", "HTODemux_Libnorm", "MULTIseqDemux"))) %>% 
  na.omit()
sigs <- map(levels(res2$method), function(x) {
  t.test(res2 %>% filter(method == "HTODemux_Libnorm") %>% pull(meanF1),
         res2 %>% filter(method == x) %>% pull(meanF1),
         paired = T,
         alternative = "greater")$p.value
})
names(sigs) <- levels(res2$method)
sigs2 <- data.frame(sigs) %>%
  t() %>% 
  as.data.frame() %>% 
  setNames("pval") %>% 
  rownames_to_column("method") %>% 
  mutate(pval = round(pval, digits = 3))
g <- ggplot(res2, aes(x = method, y = meanF1, color = method, group = method)) +
  geom_boxplot(outlier.shape = NA) +
  geom_text(data = sigs2, aes(x = method, y = 1.1, label = pval)) +
  geom_jitter(aes(shape = sample), size = 3) +
  scale_shape_manual(values=1:length(samples)) +
  theme_classic()

ggsave("F1s.pdf", height = 5, width = 8)
```

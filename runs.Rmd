```{r prep}
library(tidyverse)
library(here)
library(cowplot)
library(Seurat)
list.files("/nfs/home/rfu/projects/hashER/R/", full.names = TRUE) %>% map(., source)
data_dir <- "/gpfs/commons/groups/compbio/projects/rf_hashs/clean"
sample <- "2hash_orig"
rc <- here(data_dir, sample, "HTO_counts.csv.gz")
rh <- here(data_dir, sample, "raw_feature_bc_matrix.h5")
rr <- here(data_dir, sample, "RNA_counts.csv.gz")
wl <- here(data_dir, sample, "barcodes.tsv.gz")

```

```{r run}
run_HTODemux(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/HTODemux.csv.gz"), 
  threshold = 10
)

run_HTODemux_Libnorm(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/HTODemux_Libnorm.csv.gz")
)

run_HTODemux_Birch(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/HTODemux_GMM.csv.gz"),
  kfunc = "gmm"
)

# run_HTODemux_Libnorm_sub(
#   raw_counts = rc,
#   whitelist = wl,
#   out_name = here(data_dir, sample, "results/HTODemux_subnorm.csv.gz"),
#   threshold = 5
# )

run_demuxEM(
  raw_counts = rc,
  raw_h5 = rr,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/demuxEM.csv.gz")
)

run_HashSolo(
  raw_counts = rc,
  whitelist = wl,
  out_name = here(data_dir, sample, "results/HashSolo.csv.gz")
)
```


```{r so}
so <- readRDS(here(data_dir, sample, "so.rds"))

resall <- map(
  c(
    "HTODemux",
    "HTODemux_Libnorm",
    "demuxEM"#,
    #"HashSolo"
  ),
  function(.x) {
    parse_results(here(data_dir, sample, "results", paste0(.x, ".csv.gz")), whitelist = Cells(so)
                  ) %>% 
      setNames(str_c(.x, "_", c("global", "local")))
  }) %>% bind_cols()

so <- AddMetaData(so, resall)
```

```{r universal}
sample_desc <- hash_data %>% column_to_rownames("sample") %>% .[sample,]
ids <- sample_desc$ids %>% str_split("_") %>% unlist()
code1 <- sample_desc$code %>% str_replace("\\\\", "\\\\\\\\")
if (code1 == "") {
  code1 <- "id_hash"
}

rec <- so@meta.data %>%
  select(type = sample_desc$id_col, ends_with("_local")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(id_hash := !!rlang::parse_quo(code1, env = rlang::caller_env())) %>% 
  rename(true = type, pred = id_hash) %>%
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_miss = ifelse(true != pred, n, 0)) %>% 
  group_by(method, true) %>% 
  summarize(recall = sum(correct)/(sum(correct) + sum(wrong_miss))) %>% 
  rename(id = true) %>% 
  mutate(method = str_remove(method, "_local")) %>% 
  filter(id %in% ids)

prec <- so@meta.data %>%
  select(type = sample_desc$id_col, ends_with("_local")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(id_hash := !!rlang::parse_quo(code1, env = rlang::caller_env())) %>% 
  rename(true = type, pred = id_hash) %>%
  filter(true %in% ids) %>% 
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_call = ifelse(true != pred, n, 0)) %>% 
  group_by(method, pred) %>% 
  summarize(precision = sum(correct)/(sum(correct) + sum(wrong_call))) %>% 
  filter(!(pred %in% c("Doublet", "Negative"))) %>% 
  rename(id = pred) %>% 
  mutate(method = str_remove(method, "_local")) %>% 
  filter(id %in% ids)

f1 <- full_join(prec, rec, by = c("method", "id")) %>% 
  replace_na(list(precision = 0, recall = 0)) %>%
  mutate(F1 = 2*precision*recall/(precision+recall)) %>% 
  group_by(method) %>% 
  summarize(meanF1 = mean(F1)) %>% 
  mutate(meanF1 = ifelse(is.nan(meanF1), 0, meanF1))

type_ord <- so@meta.data %>% mutate(id := !!as.name(sample_desc$id_col)) %>% 
  select(type, id) %>%
  filter(id %in% ids) %>% 
  pull(type) %>% 
  table() %>% 
  sort() %>%
  names() %>%
  rev() # %>% intersect(ids)

df1 <- so@meta.data %>% 
  select(type, contains("_global")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "global") %>% 
  filter(!is.na(type)) %>% 
  group_by(type, method, global) %>% 
  summarise(n = n()) %>% 
  group_by(type, method) %>% 
  mutate(type = factor(type, levels = type_ord)) %>% 
  mutate(global = factor(global, levels = c("Negative", "Doublet", "Singlet"))) %>% 
  na.omit() %>% 
  mutate(freq = n/sum(n)) %>% 
  mutate(method = str_remove(method, "_global"))

cv <- df1 %>% filter(global == "Singlet") %>% group_by(method) %>% summarise(cv = sd(freq)/mean(freq)) %>% 
  mutate(cv_lab = str_c("cv=", sprintf("%.3f", round(cv, digits = 3)))) %>% 
  full_join(f1, by = "method") %>% 
  mutate(meanF1 = str_c("meanF1=", sprintf("%.3f", round(meanF1, digits = 3))))

g1 <- ggplot(df1, aes(x = type, y = freq)) +
  facet_grid(.~method) +
  geom_col(colour="black", aes(fill = global)) +
  theme_classic() +
  ylab("Hash calling") +
  theme(axis.title.x=element_blank()) +
  theme(legend.title=element_blank()) + 
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  geom_text(data = cv, aes(x = 1, y = 1.025, label = cv_lab), hjust = 0, size = 3.5) +
  geom_text(data = cv, aes(x = 1, y = 1.075, label = meanF1), hjust = 0, size = 3.5)

ggsave(paste0(sample, "_celltype.pdf"), g1, width = 10, heigh = 5)
```

```{r}
so$max_HTO <- matrixStats::colMaxs(so[["HTO"]]@counts %>% as.matrix())
so$max_HTO_norm <- matrixStats::colMaxs(so[["HTO"]]@counts %>% as.matrix())/colSums(so[["HTO"]]@counts %>% as.matrix()) * 1000
mat <- so[["HTO"]]@counts %>% as.matrix()
c2 <- matrixStats::rowMaxs(replace(t(mat), t(rbind(1:ncol(mat), max.col(t(mat)))), -Inf))

so$min_HTO <- matrixStats::colMins(so[["HTO"]]@counts %>% as.matrix())
c2m <- matrixStats::rowMins(replace(t(mat), t(rbind(1:ncol(mat), max.col(t(mat)))), Inf))

so$bg_HTO <- colSums(mat) - so$max_HTO - c2
# so$bg_HTO <- so$min_HTO + c2m
# counts_norm <- sweep(ccc,1,rowSums(ccc),FUN="/")
# counts_norm <- round(counts_norm*1000)
# so$max_HTO_normcor <- matrixStats::rowMaxs(counts_norm[Cells(so),])
set.seed(35)
df <- so@meta.data %>% 
  filter(!is.na(HTODemux_global)) %>% 
  filter(!is.na(type)) %>%
  # filter(HTODemux_local != "4-3911-MC") %>% 
  group_by(type) %>% 
  filter(n() >= 450) %>%
  sample_n(450) %>% 
  mutate(HTODemux_global = factor(HTODemux_global, levels = c("Singlet", "Negative", "Doublet")),
         HTODemux_Libnorm_global = factor(HTODemux_Libnorm_global, levels = c("Singlet", "Negative", "Doublet")))

ns <- split(df$max_HTO, df$type)
ps <- map(ns, function(x) {
  ks.test(ns[[2]], x)$p.value
}) %>% p.adjust() %>% 
  as.data.frame() %>% 
  setNames("pval") %>% 
  mutate(sig = case_when(
    pval > 0.05 ~ "insig",
    pval > 0.01 ~ "*",
    pval > 0.001~ "**",
    T ~ "***"
  )) %>% 
  mutate(pval = formatC(pval, format = "e", digits = 1)) %>% 
  rownames_to_column("type")
  
ns2 <- split(df$bg_HTO, df$type)
ps2 <- map(ns2, function(x) {
  ks.test(ns2[[2]], x)$p.value
}) %>% p.adjust() %>% 
  as.data.frame() %>% 
  setNames("pval") %>% 
  mutate(sig = case_when(
    pval > 0.05 ~ "insig",
    pval > 0.01 ~ "*",
    pval > 0.001~ "**",
    T ~ "***"
  )) %>% 
  mutate(pval = formatC(pval, format = "e", digits = 1)) %>% 
  rownames_to_column("type")

g <- ggplot(df,
       aes(x = type, y = nCount_HTO, color = HTODemux_global)) +
  ggbeeswarm::geom_quasirandom(size = 0.5, alpha = 0.5, shape = "circle") +
  theme_classic() +
  scale_y_continuous(limits = c(50, quantile(df$nCount_HTO, probs = 0.99))) +
  colorblindr::scale_color_OkabeIto(order = c(3,1,7)) +
  guides(color = guide_legend(title = "Demultiplex")) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# g2 <- ggplot(df,
#        aes(x = type, y = nCount_HTO, color = HTODemux_Libnorm_global)) +
#   ggbeeswarm::geom_quasirandom(size = 0.5, alpha = 0.5, shape = "circle") +
#   theme_classic() +
#   scale_y_continuous(limits = c(50, quantile(df$nCount_HTO, probs = 0.99))) +
#   colorblindr::scale_color_OkabeIto(order = c(3,1,7)) +
#   guides(color = guide_legend(title = "Demultiplex")) +
#   theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

g <- ggplot(df,
       aes(x = type, y = max_HTO, color = HTODemux_global)) +
  ggbeeswarm::geom_quasirandom(size = 0.5, alpha = 0.5, shape = "circle") +
  geom_text(data = ps, aes(x = type, y = quantile(df$max_HTO, probs = 0.99), label = sig), color = "black") +
  theme_classic() +
  scale_y_continuous(limits = c(10, quantile(df$max_HTO, probs = 0.99))) +
  colorblindr::scale_color_OkabeIto(order = c(3,1,7)) +
  guides(color = guide_legend(title = "Demultiplex")) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

g2 <- ggplot(df,
       aes(x = type, y = bg_HTO, color = HTODemux_Libnorm_global)) +
  ggbeeswarm::geom_quasirandom(size = 0.5, alpha = 0.5, shape = "circle") +
  geom_text(data = ps2, aes(x = type, y = quantile(df$max_HTO, probs = 0.99), label = sig), color = "black") +
  theme_classic() +
  scale_y_continuous(limits = c(10, quantile(df$max_HTO, probs = 0.99))) +
  colorblindr::scale_color_OkabeIto(order = c(3,1,7)) +
  guides(color = guide_legend(title = "Demultiplex")) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
# g3 <- ggplot(df,
#        aes(x = type, y = max_HTO_normcor, color = HTODemux_Libnorm_global)) +
#   ggbeeswarm::geom_quasirandom(size = 0.5, alpha = 0.5, shape = "circle") +
#   theme_classic() +
#   scale_y_continuous(limits = c(50, quantile(df$max_HTO, probs = 0.99))) +
#   scale_color_OkabeIto(order = c(3,1,7)) +
#   guides(color = guide_legend(title = "Demultiplex")) +
#   theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

l <- get_legend(g)
p <- plot_grid(g + NoLegend(), g2 + NoLegend(), l, nrow = 1# , labels = c("HTODemux", "LibNorm"),  label_size = 10, label_fontface = "plain", label_x = 0.6, hjust = 0.5
     )
ggsave(paste0(sample, "_quasi_res_bg.pdf"), p, width = 8, height = 4)
```

```{r 123}
rec <- so@meta.data %>%
  select(sex_dmg, contains("_local")) %>% 
  pivot_longer(-sex_dmg, names_to = "method", values_to = "id_hash") %>% 
  #mutate(method = str_remove(method, "_.+")) %>% 
  na.omit() %>% 
  rename(true = sex_dmg, pred = id_hash) %>%
  mutate(pred = str_sub(pred, 1, 1)) %>% 
  filter(true %in% c("F", "M")) %>% 
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_miss = ifelse(true != pred, n, 0)) %>% 
  group_by(method, true) %>% 
  summarize(recall = sum(correct)/(sum(correct) + sum(wrong_miss))) %>% 
  rename(id = true)

prec <- so@meta.data %>%
  select(sex_dmg, contains("_local")) %>% 
  pivot_longer(-sex_dmg, names_to = "method", values_to = "id_hash") %>% 
  #mutate(method = str_remove(method, "_.+")) %>% 
  na.omit() %>% 
  rename(true = sex_dmg, pred = id_hash) %>%
  mutate(pred = str_sub(pred, 1, 1)) %>% 
  filter(true %in% c("F", "M")) %>% 
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_call = ifelse(true != pred, n, 0)) %>% 
  group_by(method, pred) %>% 
  summarize(precision = sum(correct)/(sum(correct) + sum(wrong_call))) %>% 
  filter(pred %in% c("M", "F")) %>% 
  rename(id = pred)

f1 <- full_join(prec, rec, by = c("method", "id")) %>% 
  mutate(F1 = 2*precision*recall/(precision+recall)) %>% 
  group_by(method) %>% 
  summarize(meanF1 = mean(F1))
```

```{r 18}
rec <- so@meta.data %>%
  select(type, ends_with("_local")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(id_hash = str_remove(id_hash, "\\..+")) %>% 
  #mutate(method = str_remove(method, "_.+")) %>% 
  na.omit() %>% 
  filter(type != "other") %>% 
  rename(true = type, pred = id_hash) %>%
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_miss = ifelse(true != pred, n, 0)) %>% 
  group_by(method, true) %>% 
  summarize(recall = sum(correct)/(sum(correct) + sum(wrong_miss))) %>% 
  rename(id = true)

prec <- so@meta.data %>%
  select(type, ends_with("_local")) %>% 
  pivot_longer(-type, names_to = "method", values_to = "id_hash") %>% 
  mutate(id_hash = str_remove(id_hash, "\\..+")) %>% 
  #mutate(method = str_remove(method, "_.+")) %>% 
  na.omit() %>% 
  filter(type != "other") %>% 
  rename(true = type, pred = id_hash) %>%
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_call = ifelse(true != pred, n, 0)) %>% 
  group_by(method, pred) %>% 
  summarize(precision = sum(correct)/(sum(correct) + sum(wrong_call))) %>% 
  filter(!(pred %in% c("Doublet", "Negative"))) %>% 
  rename(id = pred)

f1 <- full_join(prec, rec, by = c("method", "id")) %>% 
  mutate(F1 = 2*precision*recall/(precision+recall)) %>% 
  group_by(method) %>% 
  summarize(meanF1 = mean(F1))

cv <- df1 %>% filter(global == "Singlet") %>% group_by(method) %>% summarise(cv = sd(freq)/mean(freq))
```

```{r p1}
rec <- so@meta.data %>%
  select(freemuxlet_id, contains("_local")) %>% 
  pivot_longer(-freemuxlet_id, names_to = "method", values_to = "id_hash") %>% 
  #mutate(method = str_remove(method, "_.+")) %>% 
  na.omit() %>% 
  filter(freemuxlet_id %in% c("3911", "9319")) %>% 
  rename(true = freemuxlet_id, pred = id_hash) %>%
  mutate(pred = str_sub(pred, 3, 6)) %>% 
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_miss = ifelse(true != pred, n, 0)) %>% 
  group_by(method, true) %>% 
  summarize(recall = sum(correct)/(sum(correct) + sum(wrong_miss))) %>% 
  rename(id = true)

prec <- so@meta.data %>%
  select(freemuxlet_id, contains("_local")) %>% 
  pivot_longer(-freemuxlet_id, names_to = "method", values_to = "id_hash") %>% 
  #mutate(method = str_remove(method, "_.+")) %>% 
  na.omit() %>% 
  filter(freemuxlet_id %in% c("3911", "9319")) %>% 
  rename(true = freemuxlet_id, pred = id_hash) %>%
  mutate(pred = str_sub(pred, 3, 6)) %>% 
  group_by(method, true, pred) %>% 
  summarize(n = n()) %>% 
  mutate(correct = ifelse(true == pred, n, 0),
         wrong_call = ifelse(true != pred, n, 0)) %>% 
  group_by(method, pred) %>% 
  summarize(precision = sum(correct)/(sum(correct) + sum(wrong_call))) %>% 
  filter(pred %in% c("3911", "9319")) %>% 
  rename(id = pred)

f1 <- full_join(prec, rec, by = c("method", "id")) %>% 
  mutate(F1 = 2*precision*recall/(precision+recall)) %>% 
  group_by(method) %>% 
  summarize(meanF1 = mean(F1))

cv <- df1 %>% filter(global == "Singlet") %>% group_by(method) %>% summarise(cv = sd(freq)/mean(freq))
```